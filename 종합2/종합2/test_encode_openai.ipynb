{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50079d25-aabe-4d3f-9461-a2a8fa9f7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# token encode/decode\n",
    "\n",
    "# 1개의 토큰은 1개의 엠베딩벡터로 전환되고\n",
    "# 1개의 글자는 1개 이상의 토큰으로 변환되고\n",
    "# 1개의 토큰은 1개이상의 글자(영어,한글포함)으로 만들어진다.\n",
    "\n",
    "# 이렇게 만들어주는 알고리즘은 BPE이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e84514-d93d-431a-9ff2-1128fd680a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"/home/mhkwon/.env\")\n",
    "\n",
    "import os\n",
    "\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "print(HF_TOKEN)\n",
    "\n",
    "#from huggingface_hub import login\n",
    "#hf_token = login(token=HF_TOKEN, add_to_git_credential=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a5b042f-2484-4c55-918b-88d178cb4ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__name__',\n",
       " '__doc__',\n",
       " '__package__',\n",
       " '__loader__',\n",
       " '__spec__',\n",
       " '__path__',\n",
       " '__file__',\n",
       " '__cached__',\n",
       " '__builtins__',\n",
       " '_tiktoken',\n",
       " 'core',\n",
       " 'Encoding',\n",
       " 'registry',\n",
       " 'model',\n",
       " 'encoding_for_model',\n",
       " 'encoding_name_for_model',\n",
       " 'get_encoding',\n",
       " 'list_encoding_names',\n",
       " '__version__']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Successfully installed tiktoken-0.8.0\n",
    "\n",
    "import tiktoken\n",
    "#print(tiktoken.__version__)\n",
    "tiktoken.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8840b2af-98bb-4087-b972-5d0050dd496a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt2', 'r50k_base', 'p50k_base', 'p50k_edit', 'cl100k_base', 'o200k_base']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiktoken.list_encoding_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55222485-42b9-42eb-a952-20fa350d9004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Encoding 'o200k_base'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiktoken.encoding_for_model(\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7801202c-3907-4510-9ffe-9724ef2950bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model GPT-4o has internally <Encoding 'o200k_base'>\n",
      "model GPT-4o mini has internally <Encoding 'o200k_base'>\n",
      "model GPT-3.5 Turbo has internally <Encoding 'o200k_base'>\n",
      "model chatgpt-4o-latest has internally <Encoding 'o200k_base'>\n",
      "model gpt-4o-audio-preview has internally <Encoding 'o200k_base'>\n",
      "model o1-mini has internally <Encoding 'o200k_base'>\n",
      "model o1-preview has internally <Encoding 'o200k_base'>\n",
      "model gpt-4-turbo has internally <Encoding 'o200k_base'>\n",
      "model dall-e-3 has internally <Encoding 'o200k_base'>\n"
     ]
    }
   ],
   "source": [
    "# 다음모델들은 모두 최신버전인 'o200k_base'로 만들어져 있다.\n",
    "\n",
    "models_made_by_openai = [\"GPT-4o\", \n",
    "                         \"GPT-4o mini\", \n",
    "                         \"GPT-3.5 Turbo\", \n",
    "                         \"chatgpt-4o-latest\", \n",
    "                         \"gpt-4o-audio-preview\",\n",
    "                         \"o1-mini\",\n",
    "                         \"o1-preview\",\n",
    "                         \"gpt-4-turbo\",\n",
    "                         \"dall-e-3\",\n",
    "                        ]\n",
    "\n",
    "for mm in models_made_by_openai:\n",
    "    print(f\"model {mm} has internally {tiktoken.encoding_for_model('gpt-4o-mini')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32cf1299-3c75-402d-8112-a1f8743a6622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model gpt-4o-mini has this o200k_base\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[14307, 171731, 13, 70135, 12652, 57622, 27001]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model가 default로 사용하는 encoding으로 가져오는 명령어\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "text = \"안녕하세요. 좋은 아침입니다\"\n",
    "\n",
    "try:\n",
    "    encoding_name = tiktoken.encoding_name_for_model(model_name)\n",
    "    print(f\"model {model_name} has this {encoding_name}\")\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "except Exception as e:\n",
    "    encoding_name = tiktoken.encoding_name_for_model(model_name, \"cl100k_base\")  # Default to cl100k_base if not found\n",
    "    print(f\"model {model_name} has this {encoding_name}\")\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    logging.error(f\"num_tokens_from_string: Error getting encoding for model {model_name}: {e}, defaulting to cl100k_base\")\n",
    "\n",
    "tokens = encoding.encode(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "369e9c4f-0ff2-49e9-96e5-d12e407353d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83, 8251, 2488, 382, 2212, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.encode(\"tiktoken is great!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ab1c41b-98a4-4912-8f90-019c24682606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tiktoken is great!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode([83, 8251, 2488, 382, 2212, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2fd4f5-2c80-4862-8839-9508e79a5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/weikang-wang/ChatGPT-Vocabulary/blob/main/cl100k_base_vocab.json\n",
    "\n",
    "{\n",
    "    \"0\": \"!\",\n",
    "    \"1\": \"\\\"\",\n",
    "    \"2\": \"#\",\n",
    "    \"3\": \"$\",\n",
    "    \"4\": \"%\",\n",
    "\n",
    "    \"12\": \"-\",\n",
    "    \"13\": \".\",\n",
    "    \"14\": \"/\",\n",
    "    \"15\": \"0\",\n",
    "    \"16\": \"1\",\n",
    "    \"17\": \"2\",\n",
    "\n",
    "    \"22\": \"7\",\n",
    "    \"23\": \"8\",\n",
    "    \"24\": \"9\",\n",
    "    \"25\": \":\",\n",
    "    \"26\": \";\",\n",
    "    \"27\": \"<\",\n",
    "....\n",
    "    \"71149\": \"-_\",\n",
    "    \"71150\": \" Structures\",\n",
    "    \"71151\": \" souvent\",\n",
    "    \"71152\": \"Specify\",\n",
    "    \"71153\": \"(pipe\",\n",
    "    \"71154\": \" fracking\",\n",
    "    \"71155\": \" GPA\",\n",
    "    \"71156\": \" bele\",\n",
    "    \"71157\": \"\\t\\t\\t\\t\\t\\t\\t   \",\n",
    "    \"71158\": \" Minority\",\n",
    "    \"71159\": \" tud\",\n",
    "    \"71160\": \" openness\",\n",
    "    \"71161\": \" Illustrated\",\n",
    "    \"71162\": \" oxidation\",\n",
    "    \"71163\": \" NK\",\n",
    "....\n",
    "    \"100249\": \";d\",\n",
    "    \"100250\": \".allowed\",\n",
    "    \"100251\": \"(newUser\",\n",
    "    \"100252\": \" merciless\",\n",
    "    \"100253\": \".WaitFor\",\n",
    "    \"100254\": \" daycare\",\n",
    "    \"100255\": \" Conveyor\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81facceb-6b2c-4e4c-ac5e-3ce10be9c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Comparing encodings\n",
    "\n",
    "\n",
    "def compare_encodings(example_string: str) -> None:\n",
    "    \"\"\"Prints a comparison of three string encodings.\"\"\"\n",
    "    # print the example string\n",
    "    print(f'\\nExample string: \"{example_string}\"')\n",
    "    # for each encoding, print the # of tokens, the token integers, and the token bytes\n",
    "    encoding_list = tiktoken.list_encoding_names()\n",
    "    \n",
    "    for encoding_name in encoding_list:\n",
    "        encoding = tiktoken.get_encoding(encoding_name)\n",
    "        token_integers = encoding.encode(example_string)\n",
    "        num_tokens = len(token_integers)\n",
    "        token_bytes = [encoding.decode_single_token_bytes(token) for token in token_integers]\n",
    "        print()\n",
    "        print(f\"{encoding_name}: {num_tokens} tokens\")\n",
    "        print(f\"token integers: {token_integers}\")\n",
    "        print(f\"token bytes: {token_bytes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2c33600-008b-4636-a446-223946c10a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: \"antidisestablishmentarianism\"\n",
      "\n",
      "gpt2: 5 tokens\n",
      "token integers: [415, 29207, 44390, 3699, 1042]\n",
      "token bytes: [b'ant', b'idis', b'establishment', b'arian', b'ism']\n",
      "\n",
      "r50k_base: 5 tokens\n",
      "token integers: [415, 29207, 44390, 3699, 1042]\n",
      "token bytes: [b'ant', b'idis', b'establishment', b'arian', b'ism']\n",
      "\n",
      "p50k_base: 5 tokens\n",
      "token integers: [415, 29207, 44390, 3699, 1042]\n",
      "token bytes: [b'ant', b'idis', b'establishment', b'arian', b'ism']\n",
      "\n",
      "p50k_edit: 5 tokens\n",
      "token integers: [415, 29207, 44390, 3699, 1042]\n",
      "token bytes: [b'ant', b'idis', b'establishment', b'arian', b'ism']\n",
      "\n",
      "cl100k_base: 6 tokens\n",
      "token integers: [519, 85342, 34500, 479, 8997, 2191]\n",
      "token bytes: [b'ant', b'idis', b'establish', b'ment', b'arian', b'ism']\n",
      "\n",
      "o200k_base: 6 tokens\n",
      "token integers: [493, 129901, 376, 160388, 21203, 2367]\n",
      "token bytes: [b'ant', b'idis', b'est', b'ablishment', b'arian', b'ism']\n"
     ]
    }
   ],
   "source": [
    "compare_encodings(\"antidisestablishmentarianism\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aef6ed5-ac8a-4925-8141-d1bdfc809df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: \"2 + 2 = 4\"\n",
      "\n",
      "gpt2: 5 tokens\n",
      "token integers: [17, 1343, 362, 796, 604]\n",
      "token bytes: [b'2', b' +', b' 2', b' =', b' 4']\n",
      "\n",
      "r50k_base: 5 tokens\n",
      "token integers: [17, 1343, 362, 796, 604]\n",
      "token bytes: [b'2', b' +', b' 2', b' =', b' 4']\n",
      "\n",
      "p50k_base: 5 tokens\n",
      "token integers: [17, 1343, 362, 796, 604]\n",
      "token bytes: [b'2', b' +', b' 2', b' =', b' 4']\n",
      "\n",
      "p50k_edit: 5 tokens\n",
      "token integers: [17, 1343, 362, 796, 604]\n",
      "token bytes: [b'2', b' +', b' 2', b' =', b' 4']\n",
      "\n",
      "cl100k_base: 7 tokens\n",
      "token integers: [17, 489, 220, 17, 284, 220, 19]\n",
      "token bytes: [b'2', b' +', b' ', b'2', b' =', b' ', b'4']\n",
      "\n",
      "o200k_base: 7 tokens\n",
      "token integers: [17, 659, 220, 17, 314, 220, 19]\n",
      "token bytes: [b'2', b' +', b' ', b'2', b' =', b' ', b'4']\n"
     ]
    }
   ],
   "source": [
    "compare_encodings(\"2 + 2 = 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c366b620-269c-4336-9b16-b740bf0e2e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: \"お誕生日おめでとう\"\n",
      "\n",
      "gpt2: 14 tokens\n",
      "token integers: [2515, 232, 45739, 243, 37955, 33768, 98, 2515, 232, 1792, 223, 30640, 30201, 29557]\n",
      "token bytes: [b'\\xe3\\x81', b'\\x8a', b'\\xe8\\xaa', b'\\x95', b'\\xe7\\x94\\x9f', b'\\xe6\\x97', b'\\xa5', b'\\xe3\\x81', b'\\x8a', b'\\xe3\\x82', b'\\x81', b'\\xe3\\x81\\xa7', b'\\xe3\\x81\\xa8', b'\\xe3\\x81\\x86']\n",
      "\n",
      "r50k_base: 14 tokens\n",
      "token integers: [2515, 232, 45739, 243, 37955, 33768, 98, 2515, 232, 1792, 223, 30640, 30201, 29557]\n",
      "token bytes: [b'\\xe3\\x81', b'\\x8a', b'\\xe8\\xaa', b'\\x95', b'\\xe7\\x94\\x9f', b'\\xe6\\x97', b'\\xa5', b'\\xe3\\x81', b'\\x8a', b'\\xe3\\x82', b'\\x81', b'\\xe3\\x81\\xa7', b'\\xe3\\x81\\xa8', b'\\xe3\\x81\\x86']\n",
      "\n",
      "p50k_base: 14 tokens\n",
      "token integers: [2515, 232, 45739, 243, 37955, 33768, 98, 2515, 232, 1792, 223, 30640, 30201, 29557]\n",
      "token bytes: [b'\\xe3\\x81', b'\\x8a', b'\\xe8\\xaa', b'\\x95', b'\\xe7\\x94\\x9f', b'\\xe6\\x97', b'\\xa5', b'\\xe3\\x81', b'\\x8a', b'\\xe3\\x82', b'\\x81', b'\\xe3\\x81\\xa7', b'\\xe3\\x81\\xa8', b'\\xe3\\x81\\x86']\n",
      "\n",
      "p50k_edit: 14 tokens\n",
      "token integers: [2515, 232, 45739, 243, 37955, 33768, 98, 2515, 232, 1792, 223, 30640, 30201, 29557]\n",
      "token bytes: [b'\\xe3\\x81', b'\\x8a', b'\\xe8\\xaa', b'\\x95', b'\\xe7\\x94\\x9f', b'\\xe6\\x97', b'\\xa5', b'\\xe3\\x81', b'\\x8a', b'\\xe3\\x82', b'\\x81', b'\\xe3\\x81\\xa7', b'\\xe3\\x81\\xa8', b'\\xe3\\x81\\x86']\n",
      "\n",
      "cl100k_base: 9 tokens\n",
      "token integers: [33334, 45918, 243, 21990, 9080, 33334, 62004, 16556, 78699]\n",
      "token bytes: [b'\\xe3\\x81\\x8a', b'\\xe8\\xaa', b'\\x95', b'\\xe7\\x94\\x9f', b'\\xe6\\x97\\xa5', b'\\xe3\\x81\\x8a', b'\\xe3\\x82\\x81', b'\\xe3\\x81\\xa7', b'\\xe3\\x81\\xa8\\xe3\\x81\\x86']\n",
      "\n",
      "o200k_base: 8 tokens\n",
      "token integers: [8930, 9697, 243, 128225, 8930, 17693, 4344, 48669]\n",
      "token bytes: [b'\\xe3\\x81\\x8a', b'\\xe8\\xaa', b'\\x95', b'\\xe7\\x94\\x9f\\xe6\\x97\\xa5', b'\\xe3\\x81\\x8a', b'\\xe3\\x82\\x81', b'\\xe3\\x81\\xa7', b'\\xe3\\x81\\xa8\\xe3\\x81\\x86']\n"
     ]
    }
   ],
   "source": [
    "compare_encodings(\"お誕生日おめでとう\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf64d999-78d6-4f67-966c-8fa85c540263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: \"저는회사에 버스를 타고 회사에가요\"\n",
      "\n",
      "gpt2: 45 tokens\n",
      "token integers: [168, 254, 222, 167, 232, 242, 169, 248, 234, 168, 8955, 168, 245, 238, 31619, 110, 226, 168, 232, 97, 167, 98, 120, 220, 169, 225, 222, 166, 111, 254, 220, 169, 248, 234, 168, 8955, 168, 245, 238, 166, 108, 222, 168, 248, 242]\n",
      "token bytes: [b'\\xec', b'\\xa0', b'\\x80', b'\\xeb', b'\\x8a', b'\\x94', b'\\xed', b'\\x9a', b'\\x8c', b'\\xec', b'\\x82\\xac', b'\\xec', b'\\x97', b'\\x90', b' \\xeb', b'\\xb2', b'\\x84', b'\\xec', b'\\x8a', b'\\xa4', b'\\xeb', b'\\xa5', b'\\xbc', b' ', b'\\xed', b'\\x83', b'\\x80', b'\\xea', b'\\xb3', b'\\xa0', b' ', b'\\xed', b'\\x9a', b'\\x8c', b'\\xec', b'\\x82\\xac', b'\\xec', b'\\x97', b'\\x90', b'\\xea', b'\\xb0', b'\\x80', b'\\xec', b'\\x9a', b'\\x94']\n",
      "\n",
      "r50k_base: 45 tokens\n",
      "token integers: [168, 254, 222, 167, 232, 242, 169, 248, 234, 168, 8955, 168, 245, 238, 31619, 110, 226, 168, 232, 97, 167, 98, 120, 220, 169, 225, 222, 166, 111, 254, 220, 169, 248, 234, 168, 8955, 168, 245, 238, 166, 108, 222, 168, 248, 242]\n",
      "token bytes: [b'\\xec', b'\\xa0', b'\\x80', b'\\xeb', b'\\x8a', b'\\x94', b'\\xed', b'\\x9a', b'\\x8c', b'\\xec', b'\\x82\\xac', b'\\xec', b'\\x97', b'\\x90', b' \\xeb', b'\\xb2', b'\\x84', b'\\xec', b'\\x8a', b'\\xa4', b'\\xeb', b'\\xa5', b'\\xbc', b' ', b'\\xed', b'\\x83', b'\\x80', b'\\xea', b'\\xb3', b'\\xa0', b' ', b'\\xed', b'\\x9a', b'\\x8c', b'\\xec', b'\\x82\\xac', b'\\xec', b'\\x97', b'\\x90', b'\\xea', b'\\xb0', b'\\x80', b'\\xec', b'\\x9a', b'\\x94']\n",
      "\n",
      "p50k_base: 45 tokens\n",
      "token integers: [168, 254, 222, 167, 232, 242, 169, 248, 234, 168, 8955, 168, 245, 238, 31619, 110, 226, 168, 232, 97, 167, 98, 120, 220, 169, 225, 222, 166, 111, 254, 220, 169, 248, 234, 168, 8955, 168, 245, 238, 166, 108, 222, 168, 248, 242]\n",
      "token bytes: [b'\\xec', b'\\xa0', b'\\x80', b'\\xeb', b'\\x8a', b'\\x94', b'\\xed', b'\\x9a', b'\\x8c', b'\\xec', b'\\x82\\xac', b'\\xec', b'\\x97', b'\\x90', b' \\xeb', b'\\xb2', b'\\x84', b'\\xec', b'\\x8a', b'\\xa4', b'\\xeb', b'\\xa5', b'\\xbc', b' ', b'\\xed', b'\\x83', b'\\x80', b'\\xea', b'\\xb3', b'\\xa0', b' ', b'\\xed', b'\\x9a', b'\\x8c', b'\\xec', b'\\x82\\xac', b'\\xec', b'\\x97', b'\\x90', b'\\xea', b'\\xb0', b'\\x80', b'\\xec', b'\\x9a', b'\\x94']\n",
      "\n",
      "p50k_edit: 45 tokens\n",
      "token integers: [168, 254, 222, 167, 232, 242, 169, 248, 234, 168, 8955, 168, 245, 238, 31619, 110, 226, 168, 232, 97, 167, 98, 120, 220, 169, 225, 222, 166, 111, 254, 220, 169, 248, 234, 168, 8955, 168, 245, 238, 166, 108, 222, 168, 248, 242]\n",
      "token bytes: [b'\\xec', b'\\xa0', b'\\x80', b'\\xeb', b'\\x8a', b'\\x94', b'\\xed', b'\\x9a', b'\\x8c', b'\\xec', b'\\x82\\xac', b'\\xec', b'\\x97', b'\\x90', b' \\xeb', b'\\xb2', b'\\x84', b'\\xec', b'\\x8a', b'\\xa4', b'\\xeb', b'\\xa5', b'\\xbc', b' ', b'\\xed', b'\\x83', b'\\x80', b'\\xea', b'\\xb3', b'\\xa0', b' ', b'\\xed', b'\\x9a', b'\\x8c', b'\\xec', b'\\x82\\xac', b'\\xec', b'\\x97', b'\\x90', b'\\xea', b'\\xb0', b'\\x80', b'\\xec', b'\\x9a', b'\\x94']\n",
      "\n",
      "cl100k_base: 17 tokens\n",
      "token integers: [14806, 222, 16969, 62841, 56154, 19954, 87931, 25941, 18918, 75461, 222, 35495, 99105, 56154, 19954, 20565, 36811]\n",
      "token bytes: [b'\\xec\\xa0', b'\\x80', b'\\xeb\\x8a\\x94', b'\\xed\\x9a\\x8c', b'\\xec\\x82\\xac', b'\\xec\\x97\\x90', b' \\xeb\\xb2\\x84', b'\\xec\\x8a\\xa4', b'\\xeb\\xa5\\xbc', b' \\xed\\x83', b'\\x80', b'\\xea\\xb3\\xa0', b' \\xed\\x9a\\x8c', b'\\xec\\x82\\xac', b'\\xec\\x97\\x90', b'\\xea\\xb0\\x80', b'\\xec\\x9a\\x94']\n",
      "\n",
      "o200k_base: 12 tokens\n",
      "token integers: [22316, 2770, 193186, 3107, 60761, 111241, 57380, 3956, 106666, 3107, 4081, 7952]\n",
      "token bytes: [b'\\xec\\xa0\\x80', b'\\xeb\\x8a\\x94', b'\\xed\\x9a\\x8c\\xec\\x82\\xac', b'\\xec\\x97\\x90', b' \\xeb\\xb2\\x84', b'\\xec\\x8a\\xa4\\xeb\\xa5\\xbc', b' \\xed\\x83\\x80', b'\\xea\\xb3\\xa0', b' \\xed\\x9a\\x8c\\xec\\x82\\xac', b'\\xec\\x97\\x90', b'\\xea\\xb0\\x80', b'\\xec\\x9a\\x94']\n"
     ]
    }
   ],
   "source": [
    "compare_encodings(\"저는회사에 버스를 타고 회사에가요\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fea033-57dd-4748-8d7c-83d04cb6caf1",
   "metadata": {},
   "source": [
    "![qa image](https://velog.velcdn.com/images/goggling/post/e6ceca64-6827-4d8f-bea5-e2bb33942f99/UTF8_%E1%84%80%E1%85%A9%E1%86%B7.png)\n",
    "\n",
    "\n",
    "\n",
    "유니코드 형태 : U+0000~U+007F는 로마자 기본, U+AC00~U+D7AF 한글 음절 등 U+숫자 형태로 이루어져있다. U+10FFFF까지만 이용(10진법으로는 1,114,111)\n",
    "유니코드의 역사 : 1988년 초안이 출판된 이후로, 포함되는 문자가 점점 늘어 가고있다. 자료를 확인해보니 2021년 9월22일 14.0버전이 나왔고, 159개의 언어종류(144,697개의 문자)가 포함되어있다.\n",
    "\n",
    "![qa image](https://velog.velcdn.com/images%2Fgoggling%2Fpost%2Ff187efc3-af3c-426d-8679-260ae55d4c8d%2Fimage.png)\n",
    "\n",
    "![qa image](https://velog.velcdn.com/images%2Fgoggling%2Fpost%2Fb2a72b5e-a9aa-4866-8991-e4eabcf8b0cc%2FUTF8_%E1%84%80%E1%85%A9%E1%86%B7.png)\n",
    "\n",
    "![qa image](https://velog.velcdn.com/images%2Fgoggling%2Fpost%2Fadd8c204-efaa-4b20-9881-31c63f510bae%2FUTF8_a.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0184c9cf-b6e8-44d7-a1cd-3c1996f124ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글 is True\n",
      "아아 가각 is True\n",
      "ㅂ is True\n",
      "ㄱ1111 is True\n",
      "aaaa is False\n",
      "1111 is False\n",
      "家 is False\n",
      "ㅏ is True\n",
      "★ is False\n",
      "fㄹ1212 is True\n",
      "한글 is ['0xd55c', '0xae00'] 2 bytes\n",
      "아아 가각 is ['0xc544', '0xc544', '0x20', '0xac00', '0xac01'] 4 bytes\n",
      "ㅂ is ['0x3142'] 1 bytes\n",
      "ㄱ1111 is ['0x3131', '0x31', '0x31', '0x31', '0x31'] 1 bytes\n",
      "aaaa is ['0x61', '0x61', '0x61', '0x61'] 0 bytes\n",
      "1111 is ['0x31', '0x31', '0x31', '0x31'] 0 bytes\n",
      "家 is ['0x5bb6'] 0 bytes\n",
      "ㅏ is ['0x314f'] 1 bytes\n",
      "★ is ['0x2605'] 0 bytes\n",
      "fㄹ1212 is ['0x66', '0x3139', '0x31', '0x32', '0x31', '0x32'] 1 bytes\n"
     ]
    }
   ],
   "source": [
    "# 한글 체크하는 함수\n",
    "\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "import re\n",
    "\n",
    "def hasHangul(text):\n",
    "    #Check the Python Version\n",
    "    pyVer3 =  sys.version_info >= (3, 0)\n",
    "\n",
    "    if pyVer3 : # for Ver 3 or later\n",
    "        encText = text\n",
    "    else: # for Ver 2.x\n",
    "        if type(text) is not unicode:\n",
    "            encText = text.decode('utf-8')\n",
    "        else:\n",
    "            encText = text\n",
    "\n",
    "    hanCount = len(re.findall(u'[\\u3130-\\u318F\\uAC00-\\uD7A3]+', encText))\n",
    "    return hanCount > 0\n",
    "\n",
    "# Not all sequences of bytes are valid UTF-8. A UTF-8 decoder should be prepared for:\n",
    "\n",
    "# Bytes that never appear in UTF-8: 0xC0, 0xC1, 0xF5–0xFF\n",
    "# A \"continuation byte\" (0x80–0xBF) at the start of a character\n",
    "# A non-continuation byte (or the string ending) before the end of a character\n",
    "# An overlong encoding (0xE0 followed by less than 0xA0, or 0xF0 followed by less than 0x90)\n",
    "# A 4-byte sequence that decodes to a value greater that U+10FFFF (0xF4 followed by 0x90 or greater)\n",
    "\n",
    "\n",
    "test = ['한글', '아아 가각', 'ㅂ', 'ㄱ1111', 'aaaa', '1111', '家', 'ㅏ', '★', 'fㄹ1212']\n",
    "\n",
    "for ch in test:\n",
    "    print(ch + \" is \" + str(hasHangul(ch)))\n",
    "\n",
    "\n",
    "def str2byte(text):\n",
    "    res= []\n",
    "    hancount = 0\n",
    "    for ii in range(len(text)):\n",
    "        ch = text[ii]\n",
    "        by = ord(ch)\n",
    "        res.append(hex(by))\n",
    "\n",
    "        if re.findall(u'[\\u3130-\\u318F\\uAC00-\\uD7A3]+', ch):\n",
    "            hancount += 1\n",
    "\n",
    "        #if by < 0x0080:  # ascii\n",
    "        #elif by < 0x0800: # 2byte\n",
    "        #elif by < 0x10000: # 3byte\n",
    "    return res, hancount\n",
    "\n",
    "for ch in test:\n",
    "    res, han = str2byte(ch)\n",
    "    print(f\"{ch} is {res} {han} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5b03fe-9fd5-4e66-baa9-ccb6d8dd4bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mymychabot",
   "language": "python",
   "name": "mychabot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
